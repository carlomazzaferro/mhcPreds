{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/matplotlib/__init__.py:1085: UserWarning: Duplicate key in file \"/Users/carlomazzaferro/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mhcflurry as mhc\n",
    "\n",
    "import sklearn\n",
    "import numpy\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = kim2014_train.get_allele(\"HLA-A3301\")\n",
    "new_model = mhc.class1_allele_specific.Class1BindingPredictor()\n",
    "new_model.fit_dataset(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_data = kim2014_test.get_allele(\"HLA-A3301\")\n",
    "predictions = new_model.predict(test_data.peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3040"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = '/Users/carlomazzaferro/Desktop/combined_human_class1_dataset.csv'\n",
    "\n",
    "kim2014 = mhc.dataset.Dataset.from_csv(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179692, 137654, 27680)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kim2014_full = mhc.dataset.Dataset.from_csv(\n",
    "    mhc.downloads.get_path(\"data_kim2014\", \"bdata.20130222.mhci.public.1.txt\"))\n",
    "\n",
    "kim2014_train = mhc.dataset.Dataset.from_csv(\n",
    "    mhc.downloads.get_path(\"data_kim2014\", \"bdata.2009.mhci.public.1.txt\"))\n",
    "kim2014_test = mhc.dataset.Dataset.from_csv(\n",
    "    mhc.downloads.get_path(\"data_kim2014\", \"bdata.2013.mhci.public.blind.1.txt\"))\n",
    "\n",
    "len(kim2014_full), len(kim2014_train), len(kim2014_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = kim2014_train.get_allele(\"HLA-A0101\")\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_index, kmer_affinities, combined_sample_weights, original_peptide_indices = train.kmer_index_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ic50_to_regression_target(ic50, max_ic50=50000):\n",
    "\n",
    "    log_ic50 = numpy.log(ic50) / numpy.log(max_ic50)\n",
    "    regression_target = 1.0 - log_ic50\n",
    "    # clamp to values between 0, 1\n",
    "    regression_target = numpy.maximum(regression_target, 0.0)\n",
    "    regression_target = numpy.minimum(regression_target, 1.0)\n",
    "    return regression_target\n",
    "\n",
    "def make_scores(ic50_y, ic50_y_pred, sample_weight=None, threshold_nm=500, max_ic50=50000):\n",
    "\n",
    "    y_pred = ic50_to_regression_target(ic50_y_pred, max_ic50)\n",
    "    try:\n",
    "        auc = sklearn.metrics.roc_auc_score(\n",
    "            ic50_y <= threshold_nm,\n",
    "            y_pred,\n",
    "            sample_weight=sample_weight)\n",
    "    except ValueError:\n",
    "        auc = numpy.nan\n",
    "    try:\n",
    "        f1 = sklearn.metrics.f1_score(\n",
    "            ic50_y <= threshold_nm,\n",
    "            ic50_y_pred <= threshold_nm,\n",
    "            sample_weight=sample_weight)\n",
    "    except ValueError:\n",
    "        f1 = numpy.nan\n",
    "    try:\n",
    "        tau = scipy.stats.kendalltau(ic50_y_pred, ic50_y)[0]\n",
    "    except ValueError:\n",
    "        tau = numpy.nan\n",
    "\n",
    "    return dict(\n",
    "        auc=auc,\n",
    "        f1=f1,\n",
    "        tau=tau)\n",
    "Y_combined = ic50_to_regression_target(kmer_affinities, max_ic50=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/matplotlib/__init__.py:1085: UserWarning: Duplicate key in file \"/Users/carlomazzaferro/.matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mhcflurry as mhc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import numpy\n",
    "import scipy\n",
    "import tflearn\n",
    "\n",
    "def regression_target_to_ic50(y, max_ic50=50000.0):\n",
    "    return max_ic50 ** (1.0 - y)\n",
    "\n",
    "def ic50_to_regression_target(ic50, max_ic50=50000.0):\n",
    "\n",
    "    log_ic50 = numpy.log(ic50) / numpy.log(max_ic50)\n",
    "    regression_target = 1.0 - log_ic50\n",
    "    # clamp to values between 0, 1\n",
    "    regression_target = numpy.maximum(regression_target, 0.0)\n",
    "    regression_target = numpy.minimum(regression_target, 1.0)\n",
    "    return regression_target\n",
    "\n",
    "kim2014_full = mhc.dataset.Dataset.from_csv(mhc.downloads.get_path(\"data_kim2014\", \"bdata.20130222.mhci.public.1.txt\"))\n",
    "\n",
    "kim2014_train = mhc.dataset.Dataset.from_csv(mhc.downloads.get_path(\"data_kim2014\", \"bdata.2009.mhci.public.1.txt\"))\n",
    "kim2014_test = mhc.dataset.Dataset.from_csv(mhc.downloads.get_path(\"data_kim2014\", \"bdata.2013.mhci.public.blind.1.txt\"))\n",
    "\n",
    "train = kim2014_train.get_allele(\"HLA-A0101\")\n",
    "\n",
    "X_index, kmer_affinities, combined_sample_weights, original_peptide_indices = train.kmer_index_encoding()\n",
    "Y_combined = ic50_to_regression_target(kmer_affinities, max_ic50=50000)\n",
    "\n",
    "xTr, xTe, yTr, yTe = train_test_split(X_index, Y_combined)\n",
    "\n",
    "yTr = numpy.reshape(yTr, (yTr.shape[0], 1))\n",
    "yTe = numpy.reshape(yTe, (yTe.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6520, 9) (2174, 9) (6520, 1) (2174, 1)\n"
     ]
    }
   ],
   "source": [
    "print(xTr.shape, xTe.shape, yTr.shape, yTe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3759  | total loss: \u001b[1m\u001b[32m0.05826\u001b[0m\u001b[0m | time: 2.235s\n",
      "| RMSProp | epoch: 040 | loss: 0.05826 - binary_acc: 0.0045 -- iter: 6510/6520\n",
      "Training Step: 3760  | total loss: \u001b[1m\u001b[32m0.05991\u001b[0m\u001b[0m | time: 3.263s\n",
      "| RMSProp | epoch: 040 | loss: 0.05991 - binary_acc: 0.0040 | val_loss: 0.04982 - val_acc: 0.0023 -- iter: 6520/6520\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf \n",
    "\n",
    "x = tf.placeholder(shape=(None, 9), dtype=tf.float32)\n",
    "y_ = tf.placeholder(shape=(None, 1, dtype=tf.float32)\n",
    "                    \n",
    "net = tflearn.input_data(placeholder=x)\n",
    "net = tflearn.embedding(net, input_dim=21, output_dim=32, weights_init='xavier')\n",
    "net = tflearn.fully_connected(net, 100, activation='tanh')\n",
    "net = tflearn.layers.normalization.batch_normalization(net)\n",
    "net = tflearn.dropout(net, 0.1)\n",
    "net = tflearn.fully_connected(net, 1, activation='sigmoid')\n",
    "\n",
    "# net = tflearn.batch_normalization()\n",
    "rmsprop = tflearn.RMSProp(learning_rate=0.0001, decay=0.99)\n",
    "net = tflearn.regression(net, optimizer=rmsprop,\n",
    "                         loss='mean_square')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(net, tensorboard_verbose=1)\n",
    "model.fit(xTr, yTr, n_epoch=40, validation_set=(xTe, yTe), show_metric=True,\n",
    "          batch_size=70)\n",
    "#tflearn.is_training(False)\n",
    "ps = model.predict(xTe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.max(xTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13779.433073</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9219.578326</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986.525863</td>\n",
       "      <td>3106.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236.310011</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3050.660671</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1948.502773</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.198050</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.551778</td>\n",
       "      <td>1194.731086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4758.773243</td>\n",
       "      <td>13633.749813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29.460669</td>\n",
       "      <td>22.629947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125.804885</td>\n",
       "      <td>11977.499602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>412.540918</td>\n",
       "      <td>6326.407964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1244.955004</td>\n",
       "      <td>232.949887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4577.345061</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>82.394526</td>\n",
       "      <td>66.123767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4068.927272</td>\n",
       "      <td>766.997171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>658.946843</td>\n",
       "      <td>37806.315838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2702.968660</td>\n",
       "      <td>42593.702731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2042.609800</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6692.101902</td>\n",
       "      <td>10999.568440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1668.691804</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9257.371204</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1509.116598</td>\n",
       "      <td>25052.980441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>224.821923</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>620.174833</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6746.355498</td>\n",
       "      <td>30603.094807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2965.557535</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2828.982322</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42.312515</td>\n",
       "      <td>41623.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1145.429550</td>\n",
       "      <td>23265.413115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>7643.386013</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>2872.170143</td>\n",
       "      <td>48242.236157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>1219.038526</td>\n",
       "      <td>2830.055894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>9462.043190</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>1513.688506</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>6434.791730</td>\n",
       "      <td>28676.966734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>6919.714035</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>791.785652</td>\n",
       "      <td>12878.837824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>10454.980874</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2084.537084</td>\n",
       "      <td>834.938284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>4958.198178</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>22.657123</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>8834.329317</td>\n",
       "      <td>48323.277769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>59.968730</td>\n",
       "      <td>80.561206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>15825.683799</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>568.698170</td>\n",
       "      <td>34499.992410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>219.441042</td>\n",
       "      <td>14013.135905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>4127.381436</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>35.374105</td>\n",
       "      <td>575.749722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>182.168935</td>\n",
       "      <td>29.319883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>11.173357</td>\n",
       "      <td>31.257375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>3495.495366</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>508.460647</td>\n",
       "      <td>7132.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>73.845190</td>\n",
       "      <td>472.347552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>4192.278273</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>115.993362</td>\n",
       "      <td>9074.948218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>10982.787116</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>4832.740600</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>1240.003063</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>5745.390219</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2174 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1\n",
       "0     13779.433073  20000.000000\n",
       "1      9219.578326  50000.000000\n",
       "2       986.525863   3106.005166\n",
       "3      1236.310011  50000.000000\n",
       "4      3050.660671  20000.000000\n",
       "5      1948.502773  20000.000000\n",
       "6        11.198050     33.000000\n",
       "7        41.551778   1194.731086\n",
       "8      4758.773243  13633.749813\n",
       "9        29.460669     22.629947\n",
       "10      125.804885  11977.499602\n",
       "11      412.540918   6326.407964\n",
       "12     1244.955004    232.949887\n",
       "13     4577.345061  50000.000000\n",
       "14       82.394526     66.123767\n",
       "15     4068.927272    766.997171\n",
       "16      658.946843  37806.315838\n",
       "17     2702.968660  42593.702731\n",
       "18     2042.609800  50000.000000\n",
       "19     6692.101902  10999.568440\n",
       "20     1668.691804  20000.000000\n",
       "21     9257.371204  20000.000000\n",
       "22     1509.116598  25052.980441\n",
       "23      224.821923  20000.000000\n",
       "24      620.174833  20000.000000\n",
       "25     6746.355498  30603.094807\n",
       "26     2965.557535  50000.000000\n",
       "27     2828.982322  20000.000000\n",
       "28       42.312515  41623.000000\n",
       "29     1145.429550  23265.413115\n",
       "...            ...           ...\n",
       "2144   7643.386013  20000.000000\n",
       "2145   2872.170143  48242.236157\n",
       "2146   1219.038526   2830.055894\n",
       "2147   9462.043190  20000.000000\n",
       "2148   1513.688506  50000.000000\n",
       "2149   6434.791730  28676.966734\n",
       "2150   6919.714035  20000.000000\n",
       "2151    791.785652  12878.837824\n",
       "2152  10454.980874  50000.000000\n",
       "2153   2084.537084    834.938284\n",
       "2154   4958.198178  50000.000000\n",
       "2155     22.657123    120.000000\n",
       "2156   8834.329317  48323.277769\n",
       "2157     59.968730     80.561206\n",
       "2158  15825.683799  50000.000000\n",
       "2159    568.698170  34499.992410\n",
       "2160    219.441042  14013.135905\n",
       "2161   4127.381436  50000.000000\n",
       "2162     35.374105    575.749722\n",
       "2163    182.168935     29.319883\n",
       "2164     11.173357     31.257375\n",
       "2165   3495.495366     30.000000\n",
       "2166    508.460647   7132.000000\n",
       "2167     73.845190    472.347552\n",
       "2168   4192.278273  50000.000000\n",
       "2169    115.993362   9074.948218\n",
       "2170  10982.787116  50000.000000\n",
       "2171   4832.740600  20000.000000\n",
       "2172   1240.003063  50000.000000\n",
       "2173   5745.390219  50000.000000\n",
       "\n",
       "[2174 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "ps = model.predict(xTe)\n",
    "preds = [regression_target_to_ic50(i[0]) for i in ps]\n",
    "targs = [regression_target_to_ic50(i[0]) for i in yTe]\n",
    "pandas.DataFrame([preds, targs]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [MHC_NN]",
   "language": "python",
   "name": "Python [MHC_NN]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
