{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11537, 9) (2215, 9) (11537, 1) (2215, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from amino_acid import Data\n",
    "\n",
    "tensorboard_dir = '/tmp/tflearn_logs'\n",
    "path_to_data = os.path.dirname(os.getcwd()) + '/mhcPreds/data/'\n",
    "\n",
    "train_dat = Data(path_to_data + 'train.txt', allele='HLA-A-0101')\n",
    "test_dat = Data(path_to_data + 'test.txt', allele='HLA-A*01:01')\n",
    "\n",
    "kmer, aff_kmer, idx_kmer = train_dat.kmer_index_encoding(kmer_size=9)\n",
    "aff_kmer = utils.ic50_to_regression_target(aff_kmer, max_ic50=50000)\n",
    "\n",
    "kmer_test, aff_kmer_test, idx_kmer_test = test_dat.kmer_index_encoding(kmer_size=9)\n",
    "aff_kmer_test = utils.ic50_to_regression_target(aff_kmer_test, max_ic50=50000)\n",
    "\n",
    "\n",
    "xTr, xTe, yTr, yTe = kmer, kmer_test, aff_kmer, aff_kmer_test\n",
    "\n",
    "yTr = numpy.reshape(yTr, (yTr.shape[0], 1))\n",
    "yTe = numpy.reshape(yTe, (yTe.shape[0], 1))\n",
    "\n",
    "\n",
    "print(xTr.shape, xTe.shape, yTr.shape, yTe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(20 - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "as_lists = [list(i) for i in train_dat.peptides]\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(train_dat.peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'UNK',\n",
       " 1: 'VWINNSWKF',\n",
       " 2: 'HCSQVFLKM',\n",
       " 3: 'DPKNWWHIL',\n",
       " 4: 'ALPPPPPPP',\n",
       " 5: 'EISTNIRQA',\n",
       " 6: 'EKEVVPDFY',\n",
       " 7: 'YFTFDLTAL',\n",
       " 8: 'IFFASFYYI',\n",
       " 9: 'ISEPTIHLV',\n",
       " 10: 'KYLYFIKGL',\n",
       " 11: 'AWIDNYNKF',\n",
       " 12: 'IRLRPGGKK',\n",
       " 13: 'VTYNCCDDDY',\n",
       " 14: 'MFSPIVPFW',\n",
       " 15: 'HSAEALQKY',\n",
       " 16: 'YEVPAALIL',\n",
       " 17: 'ELDEIGEDV',\n",
       " 18: 'FHSRFVQAL',\n",
       " 19: 'DTFGVIDTM'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Training RMSE (0.0, 0.35718116)\n",
      "Iter 750, Training RMSE (0.35718116, 0.29317763)\n",
      "Iter 1500, Training RMSE (0.29317763, 0.26485693)\n",
      "Iter 2250, Training RMSE (0.26485693, 0.24267817)\n",
      "Iter 3000, Training RMSE (0.24267817, 0.23147383)\n",
      "Iter 3750, Training RMSE (0.23147383, 0.22322008)\n",
      "Iter 4500, Training RMSE (0.22322008, 0.21512811)\n",
      "Iter 5250, Training RMSE (0.21512811, 0.21200696)\n",
      "Iter 6000, Training RMSE (0.21200696, 0.20870936)\n",
      "Iter 6750, Training RMSE (0.20870936, 0.20284314)\n",
      "Iter 7500, Training RMSE (0.20284314, 0.1991726)\n",
      "Iter 8250, Training RMSE (0.1991726, 0.19856678)\n",
      "Iter 9000, Training RMSE (0.19856678, 0.19605063)\n",
      "Iter 9750, Training RMSE (0.19605063, 0.1938832)\n",
      "Iter 10500, Training RMSE (0.1938832, 0.19139323)\n",
      "Iter 11250, Training RMSE (0.19139323, 0.18948692)\n",
      "Iter 12000, Training RMSE (0.18948692, 0.19026059)\n",
      "Iter 12750, Training RMSE (0.19026059, 0.18889983)\n",
      "Iter 13500, Training RMSE (0.18889983, 0.18752107)\n",
      "Iter 14250, Training RMSE (0.18752107, 0.18637794)\n",
      "Iter 15000, Training RMSE (0.18637794, 0.18533573)\n",
      "Iter 15750, Training RMSE (0.18533573, 0.18411303)\n",
      "Iter 16500, Training RMSE (0.18411303, 0.18315418)\n",
      "Iter 17250, Training RMSE (0.18315418, 0.18275744)\n",
      "Iter 18000, Training RMSE (0.18275744, 0.18271355)\n",
      "Iter 18750, Training RMSE (0.18271355, 0.18169641)\n",
      "Iter 19500, Training RMSE (0.18169641, 0.1815773)\n",
      "Iter 20250, Training RMSE (0.1815773, 0.18140925)\n",
      "Iter 21000, Training RMSE (0.18140925, 0.18032764)\n",
      "Iter 21750, Training RMSE (0.18032764, 0.17860581)\n",
      "Iter 22500, Training RMSE (0.17860581, 0.17813861)\n",
      "Iter 23250, Training RMSE (0.17813861, 0.17732659)\n",
      "Iter 24000, Training RMSE (0.17732659, 0.17670071)\n",
      "Iter 24750, Training RMSE (0.17670071, 0.17644466)\n",
      "Iter 25500, Training RMSE (0.17644466, 0.17655399)\n",
      "Iter 26250, Training RMSE (0.17655399, 0.17649958)\n",
      "Iter 27000, Training RMSE (0.17649958, 0.17602599)\n",
      "Iter 27750, Training RMSE (0.17602599, 0.17509454)\n",
      "Iter 28500, Training RMSE (0.17509454, 0.17467353)\n",
      "Iter 29250, Training RMSE (0.17467353, 0.17437088)\n",
      "Iter 30000, Training RMSE (0.17437088, 0.17408799)\n",
      "Iter 30750, Training RMSE (0.17408799, 0.17432621)\n",
      "Iter 31500, Training RMSE (0.17432621, 0.17452806)\n",
      "Iter 32250, Training RMSE (0.17452806, 0.17436267)\n",
      "Iter 33000, Training RMSE (0.17436267, 0.1735196)\n",
      "Iter 33750, Training RMSE (0.1735196, 0.17345409)\n",
      "Iter 34500, Training RMSE (0.17345409, 0.17354402)\n",
      "Iter 35250, Training RMSE (0.17354402, 0.17278835)\n",
      "Iter 36000, Training RMSE (0.17278835, 0.17233865)\n",
      "Iter 36750, Training RMSE (0.17233865, 0.17175332)\n",
      "Iter 37500, Training RMSE (0.17175332, 0.17223738)\n",
      "Iter 38250, Training RMSE (0.17223738, 0.1723236)\n",
      "Iter 39000, Training RMSE (0.1723236, 0.17266616)\n",
      "Iter 39750, Training RMSE (0.17266616, 0.17235786)\n",
      "Iter 40500, Training RMSE (0.17235786, 0.17193907)\n",
      "Iter 41250, Training RMSE (0.17193907, 0.17290446)\n",
      "Iter 42000, Training RMSE (0.17290446, 0.17254783)\n",
      "Iter 42750, Training RMSE (0.17254783, 0.17346907)\n",
      "Iter 43500, Training RMSE (0.17346907, 0.17302196)\n",
      "Iter 44250, Training RMSE (0.17302196, 0.172769)\n",
      "Iter 45000, Training RMSE (0.172769, 0.17255023)\n",
      "Iter 45750, Training RMSE (0.17255023, 0.1723904)\n",
      "Iter 46500, Training RMSE (0.1723904, 0.17229708)\n",
      "Iter 47250, Training RMSE (0.17229708, 0.17207755)\n",
      "Iter 48000, Training RMSE (0.17207755, 0.17170352)\n",
      "Iter 48750, Training RMSE (0.17170352, 0.17166919)\n",
      "Iter 49500, Training RMSE (0.17166919, 0.1715076)\n",
      "Iter 50250, Training RMSE (0.1715076, 0.17139606)\n",
      "Iter 51000, Training RMSE (0.17139606, 0.1711733)\n",
      "Iter 51750, Training RMSE (0.1711733, 0.17153648)\n",
      "Testing RMSE:[(0.17153648, 0.17159832)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(shape=(None, 9), dtype=tf.float32)\n",
    "y_ = tf.placeholder(shape=(None, 1), dtype=tf.float32)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "batch_size = 75\n",
    "epochs = 700\n",
    "lr = 0.001\n",
    "\n",
    "net = tflearn.input_data(placeholder=x)\n",
    "net = tflearn.embedding(net, input_dim=21, output_dim=32, weights_init='xavier')\n",
    "net = tflearn.bidirectional_rnn(net, tflearn.BasicLSTMCell(32), tflearn.BasicLSTMCell(32))\n",
    "net = tflearn.dropout(net, 0.2)\n",
    "net = tflearn.layers.normalization.batch_normalization(net)\n",
    "net = tflearn.dropout(net, 0.1)\n",
    "net = tflearn.fully_connected(net, 1, activation='sigmoid')\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(net - y_))\n",
    "train_op = tf.train.RMSPropOptimizer(lr).minimize(loss)\n",
    "accuracy = tf.contrib.metrics.streaming_root_mean_squared_error(net, y_)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    tflearn.is_training(True, session=sess)\n",
    "\n",
    "    for step in range(epochs):\n",
    "        total_batch = int(xTr.shape[0] / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = utils.get_batch2d(xTr, yTr, batch_size)\n",
    "            # batch_y = numpy.reshape(batch_y, (batch_x.shape[0], 1))\n",
    "\n",
    "            sess.run(train_op, feed_dict={x: batch_x, y_: batch_y})\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            # loss= sess.run(loss, feed_dict={x: batch_x, y_: batch_y})\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y_: batch_y})\n",
    "\n",
    "            print (\"Iter \" + str(step * batch_size) + \", Training RMSE \" + str(acc))\n",
    "\n",
    "    tflearn.is_training(False, session=sess)\n",
    "    acc = sess.run([accuracy], feed_dict={x: xTe, y_: yTe})\n",
    "    print('Testing RMSE:' + str(acc))\n",
    "    preds = sess.run(net, feed_dict={x: xTe})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_kmer[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2215,) (2215, 1)\n",
      "{'f1': 0.15902140672782875, 'auc': 0.822149496561144, 'tau': 0.38979771345291786}\n",
      "                 0             1\n",
      "0     13015.334351   1540.276452\n",
      "1      5946.535182   1540.276452\n",
      "2      4340.378490   1540.276452\n",
      "3      8505.968304   1540.276452\n",
      "4      7643.574561   1540.276452\n",
      "5      5281.672692   1540.276452\n",
      "6      6321.121266   1540.276452\n",
      "7     25575.574109   1540.276452\n",
      "8     14901.037929  13599.816872\n",
      "9     18351.959054  13599.816872\n",
      "10    18536.320857  13599.816872\n",
      "11    16790.411299  13599.816872\n",
      "12    18106.040977  13599.816872\n",
      "13    17836.419274  13599.816872\n",
      "14    18916.884323  13599.816872\n",
      "15    26683.457229  13599.816872\n",
      "16     1394.943069  31449.651043\n",
      "17     1491.331108  31449.651043\n",
      "18     4405.983168  31449.651043\n",
      "19     6009.022311  31449.651043\n",
      "20     6153.519629  31449.651043\n",
      "21     7807.458462  31449.651043\n",
      "22     5894.834730  31449.651043\n",
      "23    14697.488858  31449.651043\n",
      "24      361.732573   1836.812966\n",
      "25     1548.005107   1836.812966\n",
      "26     8902.368378   1836.812966\n",
      "27    12489.188121   1836.812966\n",
      "28    12489.188121   1836.812966\n",
      "29    12294.803746   1836.812966\n",
      "...            ...           ...\n",
      "2185   7082.205465   5000.000000\n",
      "2186   7043.389031     13.674191\n",
      "2187  17112.469202  50000.000000\n",
      "2188  21378.342977    293.175201\n",
      "2189   3927.337187    177.584151\n",
      "2190  20378.876545    900.000000\n",
      "2191  22499.472723   5000.000000\n",
      "2192  21134.939162  50000.000000\n",
      "2193   5929.193836  20000.000000\n",
      "2194  16660.773221  21966.406542\n",
      "2195   1048.860324    311.960710\n",
      "2196    966.258943    262.708226\n",
      "2197   2415.961054   1072.085943\n",
      "2198  21580.682493    941.770319\n",
      "2199   2807.790083    128.159011\n",
      "2200   2520.940726   1015.743556\n",
      "2201    850.902362    445.670256\n",
      "2202   4587.074753     29.954513\n",
      "2203   4315.555510  50000.000000\n",
      "2204   2175.220747      2.000000\n",
      "2205   6066.213734   5719.371446\n",
      "2206  15771.346747   6450.335425\n",
      "2207  32860.468586  50000.000000\n",
      "2208  34206.257126  50000.000000\n",
      "2209  28740.179374  47365.238990\n",
      "2210    848.182973    778.000000\n",
      "2211  33696.396736  50000.000000\n",
      "2212  19571.418822   1388.000000\n",
      "2213   4594.911176  20000.000000\n",
      "2214   8614.758261  20000.000000\n",
      "\n",
      "[2215 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "preds_ = numpy.array([utils.regression_target_to_ic50(i[0]) for i in preds])\n",
    "targs_ = numpy.array([utils.regression_target_to_ic50(i[0]) for i in yTe])\n",
    "print(targs.shape, preds.shape)\n",
    "print(utils.make_scores(targs_, preds_))\n",
    "print(pandas.DataFrame([preds_, targs_]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.295022e-307</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.582345e-286</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.547090e-312</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7.874433e-198</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.818935e-300</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.187172e-268</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.356666e-199</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.356666e-199</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.532792e-187</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.781997e-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>1.898456e-255</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>1.182252e-185</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>9.977790e-228</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.782352e-137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>8.495105e-116</td>\n",
       "      <td>2.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2205</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2215 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1\n",
       "0      0.000000e+00   0.000000e+00\n",
       "1      0.000000e+00   0.000000e+00\n",
       "2      0.000000e+00   0.000000e+00\n",
       "3      0.000000e+00   0.000000e+00\n",
       "4      0.000000e+00   0.000000e+00\n",
       "5      0.000000e+00   0.000000e+00\n",
       "6      0.000000e+00   0.000000e+00\n",
       "7      0.000000e+00   0.000000e+00\n",
       "8      0.000000e+00   0.000000e+00\n",
       "9      0.000000e+00   0.000000e+00\n",
       "10    1.295022e-307   0.000000e+00\n",
       "11     0.000000e+00   0.000000e+00\n",
       "12    1.582345e-286   0.000000e+00\n",
       "13     0.000000e+00   0.000000e+00\n",
       "14    4.547090e-312   0.000000e+00\n",
       "15     0.000000e+00   0.000000e+00\n",
       "16     0.000000e+00   0.000000e+00\n",
       "17     0.000000e+00   0.000000e+00\n",
       "18     0.000000e+00   0.000000e+00\n",
       "19     0.000000e+00   0.000000e+00\n",
       "20     0.000000e+00   0.000000e+00\n",
       "21     0.000000e+00   0.000000e+00\n",
       "22     0.000000e+00   0.000000e+00\n",
       "23     0.000000e+00   0.000000e+00\n",
       "24    7.874433e-198   0.000000e+00\n",
       "25    9.818935e-300   0.000000e+00\n",
       "26    3.187172e-268   0.000000e+00\n",
       "27    9.356666e-199   0.000000e+00\n",
       "28    9.356666e-199   0.000000e+00\n",
       "29    3.532792e-187   0.000000e+00\n",
       "...             ...            ...\n",
       "2185   0.000000e+00   0.000000e+00\n",
       "2186   0.000000e+00   2.781997e-60\n",
       "2187   0.000000e+00   0.000000e+00\n",
       "2188   0.000000e+00   0.000000e+00\n",
       "2189  1.898456e-255   0.000000e+00\n",
       "2190   0.000000e+00   0.000000e+00\n",
       "2191   0.000000e+00   0.000000e+00\n",
       "2192   0.000000e+00   0.000000e+00\n",
       "2193  1.182252e-185   0.000000e+00\n",
       "2194   0.000000e+00   0.000000e+00\n",
       "2195   0.000000e+00   0.000000e+00\n",
       "2196   0.000000e+00   0.000000e+00\n",
       "2197   0.000000e+00   0.000000e+00\n",
       "2198   0.000000e+00   0.000000e+00\n",
       "2199  9.977790e-228   0.000000e+00\n",
       "2200   0.000000e+00   0.000000e+00\n",
       "2201   0.000000e+00   0.000000e+00\n",
       "2202   0.000000e+00  8.782352e-137\n",
       "2203   0.000000e+00   0.000000e+00\n",
       "2204  8.495105e-116   2.000000e-05\n",
       "2205   0.000000e+00   0.000000e+00\n",
       "2206   0.000000e+00   0.000000e+00\n",
       "2207   0.000000e+00   0.000000e+00\n",
       "2208   0.000000e+00   0.000000e+00\n",
       "2209   0.000000e+00   0.000000e+00\n",
       "2210   0.000000e+00   0.000000e+00\n",
       "2211   0.000000e+00   0.000000e+00\n",
       "2212   0.000000e+00   0.000000e+00\n",
       "2213   0.000000e+00   0.000000e+00\n",
       "2214   0.000000e+00   0.000000e+00\n",
       "\n",
       "[2215 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "preds = [utils.regression_target_to_ic50(i) for i in preds]\n",
    "targs = [utils.regression_target_to_ic50(i[0]) for i in yTe]\n",
    "pandas.DataFrame([preds, targs]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 110.37532216,   85.19675418,  105.04591578, ...,  888.75762169,\n",
       "         89.26702684,  131.39279915])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regression_target_to_ic50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ab3517fbfc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregression_target_to_ic50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregression_target_to_ic50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myTe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ab3517fbfc39>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregression_target_to_ic50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregression_target_to_ic50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myTe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regression_target_to_ic50' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "preds = [regression_target_to_ic50(i) for i in preds]\n",
    "targs = [regression_target_to_ic50(i[0]) for i in yTe]\n",
    "pandas.DataFrame([preds, targs]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'RMSProp_6' type=NoOp>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.square(10 - 1))\n",
    "a = tf.train.RMSPropOptimizer(0.1).minimize(loss)\n",
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from amino_acid import Data\n",
    "import os\n",
    "import utils\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import pandas\n",
    "\n",
    "\n",
    "class TFLearnPepPred(object):\n",
    "    '''\n",
    "    seq2seq recurrent neural network, implemented using TFLearn.\n",
    "    '''\n",
    "    AVAILABLE_MODELS = [\"embedding_rnn\", \"embedding_attention\"]\n",
    "\n",
    "    def __init__(self, allele=None, kmer_size=9, batch_size=64, learning_rate=0.001, verbose=None, data_dir=None):\n",
    "\n",
    "        self.path_to_data = os.path.dirname(os.getcwd()) + '/mhcPreds/data/'\n",
    "        self.xTr, self.xTe, self.yTr, self.yTe = self.generate_train_test_data(allele=allele, kmer_size=kmer_size)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose or 0\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def generate_train_test_data(self, allele=None, kmer_size=9):\n",
    "\n",
    "        train_dat = Data(self.path_to_data + 'train.txt', allele=allele)\n",
    "        test_dat = Data(self.path_to_data + 'test.txt', allele=allele)\n",
    "\n",
    "        kmer, aff_kmer, idx_kmer = train_dat.kmer_index_encoding(kmer_size=9)\n",
    "        aff_kmer = utils.ic50_to_regression_target(aff_kmer, max_ic50=50000)\n",
    "\n",
    "        kmer_test, aff_kmer_test, idx_kmer_test = test_dat.kmer_index_encoding(kmer_size=kmer_size)\n",
    "        aff_kmer_test = utils.ic50_to_regression_target(aff_kmer_test, max_ic50=50000)\n",
    "\n",
    "        xTr, xTe, yTr, yTe = kmer, kmer_test, aff_kmer, aff_kmer_test\n",
    "\n",
    "        yTr = numpy.reshape(yTr, (yTr.shape[0], 1))\n",
    "        yTe = numpy.reshape(yTe, (yTe.shape[0], 1))\n",
    "\n",
    "        return xTr, xTe, yTr, yTe\n",
    "\n",
    "    def optimizer(self):\n",
    "        opt =  tflearn.RMSProp(learning_rate=0.001, decay=0.9)\n",
    "        return opt\n",
    "\n",
    "    def loss_func(self, y_pred, y_true):\n",
    "        return tf.reduce_mean(tf.square(y_pred - y_true))\n",
    "\n",
    "    def accuracy(self, y_pred, y_true):\n",
    "        return tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(y_pred, y_true))))\n",
    "    \n",
    "    def l1_norm(prediction, target, inputs):\n",
    "        return tf.reduce_sum(tf.abs(prediction - target), name='l1')\n",
    "                       \n",
    "    def model(self, type=None, mode=\"train\", num_layers=2, state_size=32, learning_rate=0.0001, tensorboard_verbose=3):\n",
    "\n",
    "        net = tflearn.input_data(shape=[None, 9])\n",
    "        net = tflearn.embedding(net, input_dim=21, output_dim=32, weights_init='xavier')\n",
    "\n",
    "        if type == 'bi_rnn':\n",
    "            out_rnn = tflearn.bidirectional_rnn(net, tflearn.BasicLSTMCell(32), tflearn.BasicLSTMCell(32))\n",
    "            \n",
    "        elif type == 'basic_lstm':\n",
    "            out_rnn = tflearn.lstm(net, 40)\n",
    "\n",
    "        elif type =='basic_rnn':\n",
    "            out_rnn = tflearn.simple_rnn(net, 40)\n",
    "\n",
    "        else:\n",
    "            out_rnn = net\n",
    "\n",
    "        net = tflearn.fully_connected(out_rnn, 100, activation='prelu')\n",
    "        net = tflearn.layers.normalization.batch_normalization(net)\n",
    "        net = tflearn.dropout(net, 0.1)\n",
    "        net = tflearn.fully_connected(net, 1, activation='sigmoid')\n",
    "\n",
    "        \"\"\"\n",
    "        single_cell = getattr(tf.contrib.rnn, cell_type)(cell_size, state_is_tuple=True)\n",
    "\n",
    "        if num_layers == 1:\n",
    "            cell = single_cell\n",
    "        else:\n",
    "            cell = tf.contrib.rnn.MultiRNNCell([single_cell] * num_layers)\n",
    "        \"\"\"\n",
    "\n",
    "        with tf.name_scope(\"TargetsData\"):  # placeholder for target variable (i.e. trainY input)\n",
    "            targetY = tf.placeholder(shape=[None, 1], dtype=tf.float32, name=\"Y\")\n",
    "\n",
    "        network = tflearn.regression(net,\n",
    "                                     placeholder=targetY,\n",
    "                                     optimizer=self.optimizer(),\n",
    "                                     learning_rate=learning_rate,\n",
    "                                     loss=self.loss_func(net, targetY),\n",
    "                                     metric=self.accuracy(net, targetY),\n",
    "                                     name=\"Y\")\n",
    "\n",
    "        model = tflearn.DNN(network, tensorboard_verbose=tensorboard_verbose)\n",
    "        return model\n",
    "\n",
    "    def train(self, model, num_epochs=20, num_points=100000, model_params=None, weights_input_fn=None,\n",
    "              validation_set=0.1, snapshot_step=5000,  weights_output_fn=None):\n",
    "        '''\n",
    "        Train model, with specified number of epochs, and dataset size.\n",
    "        Use specified model, or create one if not provided.  Load initial weights from file weights_input_fn,\n",
    "        if provided. validation_set specifies what to use for the validation.\n",
    "        Returns logits for prediction, as an numpy array of shape [out_seq_len, n_output_symbols].\n",
    "        '''\n",
    "\n",
    "        model.fit(self.xTr, self.yTr,\n",
    "                  n_epoch=num_epochs,\n",
    "                  validation_set=validation_set,\n",
    "                  batch_size=self.batch_size,\n",
    "                  shuffle=True,\n",
    "                  show_metric=True,\n",
    "                  snapshot_step=snapshot_step,\n",
    "                  snapshot_epoch=False,\n",
    "                  run_id=\"TFLearnSeq2Seq\"\n",
    "                  )\n",
    "        print (\"Done!\")\n",
    "        return model\n",
    "\n",
    "    def predict(self, model):\n",
    "        '''\n",
    "        Make a prediction, using the seq2seq model, for the given input sequence Xin.\n",
    "        If model is not provided, create one (or use last created instance).\n",
    "        Return prediction, y\n",
    "        prediction = array of integers, giving output prediction.  Length = out_seq_len\n",
    "        y = array of shape [out_seq_len, out_max_int], giving logits for output prediction\n",
    "        '''\n",
    "\n",
    "        res = model.predict(self.xTr)\n",
    "        if self.verbose > 1: print (\"prediction shape = %s\" % str(res.shape))\n",
    "\n",
    "        if self.verbose:\n",
    "            print (\"Predicted output sequence: %s\" % str(res))\n",
    "\n",
    "        return res\n",
    "\n",
    "    def scoring(self, preds):\n",
    "\n",
    "        preds = numpy.array([utils.regression_target_to_ic50(i[0]) for i in preds])\n",
    "        targs = numpy.array([utils.regression_target_to_ic50(i[0]) for i in self.yTe])\n",
    "        scores = utils.make_scores(targs, preds)\n",
    "        as_df = pandas.DataFrame([preds, targs])\n",
    "\n",
    "        return scores, as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Sqrt_14:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'Sqrt_15:0' shape=() dtype=float32>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.accuracy(10,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TFLearnPepPred.optimizer of <__main__.TFLearnPepPred object at 0x12d99fac8>>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-6fcaadedf844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFLearnPepPred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallele\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'basic_rnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-2ca540a69f20>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, num_epochs, num_points, model_params, weights_input_fn, validation_set, snapshot_step, weights_output_fn)\u001b[0m\n\u001b[1;32m    116\u001b[0m                   \u001b[0msnapshot_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                   \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                   \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TFLearnSeq2Seq\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                   )\n\u001b[1;32m    120\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0;32m--> 183\u001b[0;31m                                       self.targets)\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mval_feed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/tflearn/utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[0;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# If a dict is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "md = TFLearnPepPred(allele=None, kmer_size=9, batch_size=64, learning_rate=0.001, verbose=3, data_dir=None)\n",
    "model = md.model(type='basic_rnn', mode=\"train\", num_layers=2, state_size=10)\n",
    "trained = md.train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-7c2280b1e440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-158-980f14ea9996>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, num_epochs, num_points, model_params, weights_input_fn, validation_set, snapshot_step, weights_output_fn)\u001b[0m\n\u001b[1;32m    113\u001b[0m                   \u001b[0msnapshot_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnapshot_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                   \u001b[0msnapshot_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                   \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TFLearnSeq2Seq\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                   )\n\u001b[1;32m    117\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/tflearn/models/dnn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_inputs, Y_targets, n_epoch, validation_set, show_metric, batch_size, shuffle, snapshot_epoch, snapshot_step, excl_trainops, validation_batch_size, run_id, callbacks)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# TODO: check memory impact for large data and multiple optimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         feed_dict = feed_dict_builder(X_inputs, Y_targets, self.inputs,\n\u001b[0;32m--> 183\u001b[0;31m                                       self.targets)\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mfeed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mval_feed_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carlomazzaferro/anaconda/envs/MHC_NN/lib/python3.5/site-packages/tflearn/utils.py\u001b[0m in \u001b[0;36mfeed_dict_builder\u001b[0;34m(X, Y, net_inputs, net_targets)\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                 \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# If a dict is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [MHC_NN]",
   "language": "python",
   "name": "Python [MHC_NN]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
